{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **Deep neural network under-sampled image reconstruction for X-Ray tomography**\n",
    "### *PyTorch 1.7*\n",
    "\n",
    "*nicolas.ducrosr@creatis.insa-lyon.fr*\n",
    "    \n",
    "##  <span style=\"color:brown\"> Imports needed lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import fht\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.io as sio\n",
    "import scipy.linalg as lin\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import model_Radon_DCAN as model_radon\n",
    "import h5py as h5\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import radon, rescale\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Considered parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Acquisition\n",
    "img_size = 64 # image size\n",
    "pixel_size = 64 #Number of pixels of the sensor\n",
    "\n",
    "#- Using CPU or GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **1 - Computed Tomography (CT) and Radon operator**\n",
    "\n",
    "## Computed Tomography (CT)\n",
    "Computed tomography (CT) is an imaging modality that reconstructs 2D or 3D objects from attenuation measurements. CT is a technique used in non-destructive inspection but most notably in medical imaging, where attenuation allows the type of tissue (e.g., bone, soft tissue) and structures (e.g., tumors) to be identified. The image formation process can be modelled by the Radon transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Radon transform\n",
    "The Radon transform is an integral transform that returns line integrals over hyperplanes (e.g., along lines for a 2D object). We illustrate this process in a discrete setting below. We considering a discrete object image and rays with a finite widths that projected onto a set of pixels at discrete locations. The attenuation measured in all pixels under several view angles is called sinogram. \n",
    "\n",
    "<img src=\"fig/tomo.png\" alt=\"Projections schem\" style=\"width: 80%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Considering a point object (i.e., only one nonzero pixel), what does the sinogram look like ?**\n",
    "    \n",
    "<font color='blue'>**Q: Complete the code below to create a (img_size x img_size) image with only one pixel (say the one at location [5,5]) set to 1. All others pixel intensites are set to 0.**</font>\n",
    "\n",
    "<font color='red'>**A: See the plot**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector with acquired angles\n",
    "theta = np.linspace(0., 180., 181)\n",
    "\n",
    "#Creation of an object image with a single activated pixel\n",
    "example = np.zeros((img_size, img_size)) #COMPLETE\n",
    "example[5,5] = 1 # -----------------------DELETE HERE\n",
    "\n",
    "#Simulation of scan via radon function\n",
    "sinogram = radon(example, theta, circle=False)\n",
    "sinogram = rescale(sinogram, scale=(pixel_size/sinogram.shape[0],1), mode='reflect', multichannel=False)\n",
    "\n",
    "#Plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.5))\n",
    "ax1.set_title(\"Original\")\n",
    "ax1.imshow(example, cmap=plt.cm.Greys_r)\n",
    "\n",
    "ax2.set_title(\"Radon transform\\n(Sinogram)\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "ax2.imshow(sinogram, cmap=plt.cm.Greys_r,\n",
    "           extent=(0, 180, 0, sinogram.shape[0]), aspect='auto')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Explain the 'sinogram' terminology.**</font>\n",
    "\n",
    "<font color='red'> **A:The sinogram terminology comes from the sine shape described by the sources.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> The radon operator\n",
    "We aim at building a neural network to reconstruct an image given measurements $m$. For computational purpose, it can be interesting to consider the Radon transform as a matrix multiplication between a forward operator $A$ and the flattened true image $f$.\n",
    "\n",
    "The corresponding matrix is illustrated below. In this example, each column accounts for the flattened sinogram computed for the corresponding pixel.\n",
    "    \n",
    "<img src=\"fig/def var.jpg\" alt=\"m and A\" style=\"width: 50%;\"/> <img src=\"fig/dim.jpg\" alt=\"forward operator\" style=\"width: 49%;\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:brown\"> Creating the operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective here is to create this forward operator $A$ on a toy example for images of size $16\\times 16$. \n",
    "\n",
    "<font color='blue'>Q: **Based on the explanation above, complete the code below to create the matrix $A_{\\text{example}}$**</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb of angles of acquisition\n",
    "total_angles = 181\n",
    "\n",
    "# Define an empty matrix A\n",
    "img_size_example = 16 #COMPLETE\n",
    "pixel_size_example = 16 #COMPLETE\n",
    "A_example = np.zeros((pixel_size_example*total_angles, img_size_example*img_size_example)) #COMLPLETE\n",
    "\n",
    "# Fill the matrix \n",
    "for i in range(img_size_example):\n",
    "    for j in range(img_size_example):\n",
    "        # Activating a single pixel of the object image\n",
    "        image = np.zeros((img_size_example,img_size_example)) ##COMPLETE\n",
    "        image[i,j] = 1 ##COMLPETE\n",
    "        \n",
    "        # Radon transform\n",
    "        sinogram = radon(image, theta, circle=False) ##COMPLETE\n",
    "        sinogram = rescale(sinogram, scale=(pixel_size_example/sinogram.shape[0],1), mode='reflect', multichannel=False)\n",
    "        ## COMPLETE above\n",
    "        #Juxtaposing results in A matrix \n",
    "        A_example[:,pixel_size_example*i+j] = np.reshape(sinogram, (pixel_size_example*total_angles, )) ##COMLPETE\n",
    "\n",
    "# A matrix visualisation\n",
    "fig, ax = plt.subplots(figsize=(100, 2))\n",
    "ax.imshow(np.transpose(A_example))\n",
    "ax.set_title(\"A operator\")\n",
    "ax.set_xlabel(\"Flattened sinograms (D pixels per angle)\")\n",
    "ax.set_ylabel(\"Position in object (pixels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q: Interpret the matrix** $\\mathbf{A}$**. Especially, why is it sparse?**\n",
    "</font>\n",
    "\n",
    "<font color='red'> **Each row corresponds to one pixel position in the image domain. Each column corresponds to a pixel detector at one angle position. The value at each position $(i,j)$ in the forward matrix corresponds to the contribution of the image pixel $i$ in the sinogram pixel $j$. The matrix is sparse because at a given angular position, only few pixels contribute to the value of one detector pixel. For instance when the detector is at angle 0, there are 16/256 pixels contributing for each detector pixel (1 out of 16 values of the image vector), that we can observe with the \"lines\" in the forward matrix.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:brown\"> Testing the resulting matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Compute the code below to check that the created matrix matches the Radon transform. For this, compare sinograms obtained with the two operators.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = shepp_logan_phantom()\n",
    "phantom = rescale(phantom, scale=(img_size_example/phantom.shape[0]), mode='reflect', multichannel=False)\n",
    "\n",
    "# Radon transform with skimage function\n",
    "radon1 = radon(phantom, theta, circle=False) ##COMPLETE\n",
    "radon1 = rescale(radon1, scale=(pixel_size_example/radon1.shape[0], 1), mode='reflect', multichannel=False)\n",
    "## COMPLETE ABOVE\n",
    "\n",
    "# Radon transform with A matrix - Maybe do with numpy???\n",
    "radon2 = torch.mv(torch.Tensor(A_example),torch.flatten(torch.tensor(phantom).float()))\n",
    "radon2 = radon2.view(img_size_example, 181)\n",
    "\n",
    "# Plots ##COMPLETE THE PLOT\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.5))\n",
    "ax1.set_title(\"Sinogram w Radon transform\")\n",
    "ax1.set_xlabel(\"Projection angle (deg)\")\n",
    "ax1.set_ylabel(\"Projection position (pixels)\")\n",
    "ax1.imshow(radon1, cmap=plt.cm.Greys_r, extent=(0, 180, 0, radon1.shape[0]), aspect='auto')\n",
    "\n",
    "ax2.set_title(\"Sinogram w matrix $A$\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "ax2.imshow(radon2, cmap=plt.cm.Greys_r, extent=(0, 180, 0, radon2.shape[0]), aspect='auto')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:brown\"> Inverse matrix\n",
    "Now the aim is to retrieve $f$ from the measurements $m$, as it is the case in practice. A first idea could be to invert the matrix $A$. However the operator is not square and we will consider using the Moore-Penrose pseudo inverse.\n",
    "\n",
    "The pseudo-inverse of a matrix $A$, denoted $A^\\dagger$, is the matrix such that $\\bar{x} = A^\\dagger b$ if $\\bar{x}$ is the solution of the least-squares minimization of the problem $Ax = b$.\n",
    "\n",
    "<img src=\"fig/ill_pinv.png\" alt=\"m and A\" style=\"width: 100%;\"/>    \n",
    "    \n",
    "<!-- It can be shown that if $Q_1 \\Sigma Q_2^T = A$ is the singular value decomposition of A, then $A^\\dagger = Q_2 \\Sigma^+ Q_1^T$, where $Q_{1,2}$ are orthogonal matrices, $\\Sigma$ is a diagonal matrix consisting of $A$’s so-called singular values (followed typically by zeros), and $\\Sigma^\\dagger$ is the diagonal matrix consisting of the reciprocals of $A$’s singular values (again, followed by zeros). [1]\n",
    "\n",
    "[1] G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pp. 139-142. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus there are two ways to retrieve $f$ from $m$ : solve the least square minimization problem or directly compute the pseudoinverse and apply it on the measurement data.\n",
    "\n",
    "<font color='blue'>**Q: Thanks to scipy.linalg library, implement the two methods and compare the times of execution for both of them.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the computed sinogram\n",
    "sinogram = np.reshape(radon1, (-1, 1))\n",
    "\n",
    "# Compute the pseudoinverse\n",
    "pinv = lin.pinv(A_example)\n",
    "\n",
    "# Rconstruct with pseudoinverse \n",
    "## COMPLETE BLOCK\n",
    "t1 = time.perf_counter()\n",
    "rec_pi = np.reshape(np.dot(pinv, sinogram), (img_size_example,img_size_example))\n",
    "t1 = time.perf_counter() - t1\n",
    "\n",
    "# Reconstruct with solver\n",
    "## COMPLETE BLOCK\n",
    "t2 = time.perf_counter()\n",
    "rec_solv = np.reshape(lin.lstsq(A_example, sinogram)[0], (img_size_example,img_size_example))\n",
    "t2 = time.perf_counter() - t2\n",
    "\n",
    "# Display results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4.5))\n",
    "ax1.set_title(\"Ground Truth\")\n",
    "ax1.imshow(phantom, cmap=plt.cm.Greys_r, extent=(0, 180, 0, phantom.shape[0]), aspect='auto')\n",
    "\n",
    "ax2.set_title(f'Reco with pseudoinverse \\n Time : {t1:.4f} s')\n",
    "ax2.imshow(rec_pi, cmap=plt.cm.Greys_r, extent=(0, 180, 0, rec_pi.shape[0]), aspect='auto')\n",
    "\n",
    "ax3.set_title(f'Reco with solver \\n Time : {t2:.4f} s')\n",
    "ax3.imshow(rec_solv, cmap=plt.cm.Greys_r, extent=(0, 180, 0, rec_solv.shape[0]), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Which method is faster? According to you, what are the limits of this method of reconstruction?**</font>\n",
    "\n",
    "\n",
    "<font color='red'>**A: reconstruction with pseudoinverse is faster than with the solver. Limits include: dealing with huge matrices in the case of larger images (pb of memory and time), cases where there are less acquisition angles, problem of noise,...**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **2 - Compressed Acquisition**\n",
    "\n",
    "Now we have the forward matrix $A$ and we are able to compute the pseudo inverse to solve the backprojection problem. However, in reality, we might not have measurements/projections acquired with a step size of 1 degree. \n",
    "\n",
    "We are now going to investigate the behaviour of the pseudoinverse based reconstruction method when the number of projection decreases.\n",
    "    \n",
    "<img src=\"fig/Explain_a_reduced.PNG\" alt=\"m and A\" style=\"width: 100%;\"/>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to work now with images of size $64 \\times 64$, forward matrix and the corresponding pseudoinverse were pre-computed for the full angle data. We will consider a case where the acquisition was performed with less projection data (20 angles).\n",
    "\n",
    "<font color='blue'> **Questions**:\n",
    "- <font color='blue'>Load the pre-computed matrices. </font>\n",
    "- <font color='blue'>Compute $A_{\\text{reduced}}$ obtai<font color='blue'>ned by removing angles so that projections are obtained for only 20 angles.</font>\n",
    "- <font color='blue'>Compute the pseudoinverse of the r<font color='blue'>educed forward matrix.</font>\n",
    "- <font color='blue'> Check the Dimensions of $\\mathbf{A}_\\text{reduced}$. Is it what you expected?</font>\n",
    "\n",
    "<font color='red'>**A: Areduced should be of size (64x64, 20x64)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path\n",
    "data_root = '/floyd/input/dlmis21_reconstruction_hands_on_vf/'\n",
    "saved_data = data_root + 'matrices/'\n",
    "\n",
    "# Load forward matrix with full angle data\n",
    "radon_matrix_path = saved_data + 'Q{}_D{}.mat'.format(img_size, pixel_size)\n",
    "H = sio.loadmat(radon_matrix_path)\n",
    "A = H.get(\"A\")\n",
    "A = np.array(A)\n",
    "A = torch.from_numpy(A)\n",
    "A = A.type(torch.FloatTensor)\n",
    "\n",
    "# Load the corresponding pseudoinverse\n",
    "pinv_matrix_path = saved_data + 'pinv_Q{}_D{}.mat'.format(img_size, pixel_size)\n",
    "H = h5.File(pinv_matrix_path, 'r')\n",
    "pinvA = H.get(\"A_pinv\")\n",
    "pinvA = np.array(pinvA)\n",
    "pinvA = np.transpose(pinvA)\n",
    "pinvA = torch.from_numpy(pinvA)\n",
    "pinvA = pinvA.type(torch.FloatTensor)\n",
    "\n",
    "# Compute the reduced forward matrix\n",
    "nbAngles = 20 ##COMPLETE THIS LINE ONLY\n",
    "Areduced = model_radon.radonSpecifyAngles(A, model_radon.generateAngles(nbAngles))\n",
    "Areduced = Areduced.type(torch.FloatTensor)\n",
    "\n",
    "# Compute the corresponding pseudoinverse\n",
    "## COMPLETE THE BLOCK\n",
    "if device == \"cuda:0\":\n",
    "    pinvAreduced = lin.pinv(Areduced.cpu().numpy())\n",
    "else:\n",
    "    pinvAreduced = lin.pinv(Areduced.numpy())\n",
    "    \n",
    "pinvAreduced = torch.from_numpy(pinvAreduced)\n",
    "pinvAreduced = pinvAreduced.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that forward matrices and their pseudo inverse have been loaded/computed, we will study the quality of the corresponding reconstructions on some toy image.\n",
    "\n",
    "<font color='blue'> **Q: Complete the code below to** </font>\n",
    "- <font color='blue'> Compute the sinograms with both forward operators</font>\n",
    "- <font color='blue'>Reconstruct the image with the corresponding pseudoinverse. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "im = Image.open(\"fig/image.png\")\n",
    "im = ImageOps.grayscale(im)\n",
    "\n",
    "# Preprocess the image\n",
    "im_array = np.asarray(im)\n",
    "im_array = im_array.astype(np.float32)\n",
    "im_array = 2*(im_array)/255 - np.ones([64,64])\n",
    "\n",
    "# Pass it as a torch object\n",
    "f = torch.from_numpy(im_array)\n",
    "f = f.view(1,img_size**2);\n",
    "f = f.t()\n",
    "f = f.type(torch.FloatTensor)\n",
    "\n",
    "# Simulate the measurements with full angle and limited angle configurations\n",
    "m_reduced = torch.mv(Areduced,f[:,0]) ##COMPLETE\n",
    "m_perfect = torch.mv(A,f[:,0]) ##COMPLETE\n",
    "\n",
    "# Reconstruct in the case of full angle data\n",
    "f_perfect = torch.mv(pinvA, m_perfect) ##COMPLETE #should be a 1D vector here\n",
    "# Resize to a 2D shape\n",
    "f_perfect_array = model_radon.vector2matrix(f_perfect, [img_size,img_size])\n",
    "f_perfect_array = np.transpose(f_perfect_array)\n",
    "\n",
    "# Reconstruct in the case of limited angle data\n",
    "f_reconstruct = torch.mv(pinvAreduced ,m_reduced) ##COMPLETE\n",
    "# Resize to a 2D shape\n",
    "f_reconstruct_array = model_radon.vector2matrix(f_reconstruct, [img_size,img_size])\n",
    "f_reconstruct_array = np.transpose(f_reconstruct_array)\n",
    "\n",
    "# Display results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 4.5))\n",
    "\n",
    "ax1.set_title(\"Input image\")\n",
    "pcm1 = ax1.imshow(im_array, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.set_title(\"Sinogram\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "m_perfect_array = model_radon.vector2matrix(m_perfect, [total_angles,pixel_size])\n",
    "pcm2 = ax2.matshow(m_perfect_array, cmap='gray')\n",
    "\n",
    "ax3.set_title(\"Reconstructed image with 181 angles measured\")\n",
    "pcm3 = ax3.matshow(f_perfect_array, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "fig.colorbar(pcm1,ax=ax1)\n",
    "fig.colorbar(pcm2,ax=ax2)\n",
    "fig.colorbar(pcm3,ax=ax3)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig2, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25, 4.5))\n",
    "\n",
    "ax1.set_title(\"Input image\")\n",
    "pcm1 = ax1.matshow(im_array, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.set_title(\"Sinogram\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "m_array = model_radon.vector2matrix(m_reduced, [nbAngles,pixel_size])\n",
    "pcm2 = ax2.matshow(m_array, cmap='gray')\n",
    "\n",
    "ax3.set_title(\"Reconstructed image with 20 angles measured\")\n",
    "pcm3 = ax3.matshow(f_reconstruct_array, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "fig2.colorbar(pcm1,ax=ax1)\n",
    "fig2.colorbar(pcm2,ax=ax2)\n",
    "fig2.colorbar(pcm3,ax=ax3)\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q: Interpret the results. Is the pseudoinverse based reconstruction method still satisfying with 20 measurement angles?**</font>\n",
    "\n",
    "<font color='red'>**A: Visible artefacts, loss of details...**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Reconstructed images for multiple numbers of acquisition angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen the degradation of the image when reducing the number of measurement angles. To further study this degradation process, we will now repeat the steps for different numbers of projection angles.\n",
    "\n",
    "<font color='blue'> For the different number of angles shown in ```listAngles```, perform </font>\n",
    "- <font color='blue'>The $A_{\\text{reduced}}$ and its pseudoinverse computation</font>\n",
    "- <font color='blue'>The simulation of the measurement data</font>\n",
    "- <font color='blue'>The image reconstruction </font>\n",
    "\n",
    "For computational reasons, results with 100, 140 and 180 angles were pre-computed and can be compared with the obtained reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listAngles = [5, 10, 20, 40, 60]\n",
    "\n",
    "print('Computation is on going, it might take up to 1 minute...')\n",
    "##PERFORM THE WHOLE LOOP\n",
    "for ang in listAngles:\n",
    "    # Compute Areduced\n",
    "    Areduced = model_radon.radonSpecifyAngles(A, model_radon.generateAngles(ang))\n",
    "    Areduced = Areduced.type(torch.FloatTensor)\n",
    "    \n",
    "    # Compute the pseudoinverse\n",
    "    if device == \"cuda:0\":\n",
    "        pinvAreduced = lin.pinv(Areduced.cpu().numpy())\n",
    "    else:\n",
    "        pinvAreduced = lin.pinv(Areduced.numpy())\n",
    "    pinvAreduced = torch.from_numpy(pinvAreduced)\n",
    "    pinvAreduced = pinvAreduced.type(torch.FloatTensor)\n",
    "    \n",
    "    # Simulate the measurements\n",
    "    m = torch.mv(Areduced,f[:,0])\n",
    "    \n",
    "    # Reconstruct the image\n",
    "    f_reconstruct = torch.mv(pinvAreduced,m)\n",
    "    \n",
    "    # Reshape into a 2D mage\n",
    "    f_reconstruct_array = model_radon.vector2matrix(f_reconstruct, [img_size,img_size])\n",
    "    f_reconstruct_array = np.transpose(f_reconstruct_array)\n",
    "    \n",
    "    # Display results\n",
    "    plt.imshow(f_reconstruct_array, cmap='gray')\n",
    "    plt.title(f'Reconstruction w {ang} angles measured')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# Display the pre-computed reconstructions\n",
    "supp_angles = [100, 140, 180]\n",
    "path_rec = data_root + 'reconstructed/'\n",
    "for ang in supp_angles:\n",
    "    f_reconstruct_array = np.load(path_rec + f'reconstructed_{ang}_angles.npy')\n",
    "    plt.imshow(f_reconstruct_array, cmap='gray')\n",
    "    plt.title(\"Reconstruction w {} angles measured\".format(ang))\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Q: According to you, what is the minimum number of measurement angles that allows to use the pseudoinverse as a satisfying reconstruction method?** </font>\n",
    "\n",
    "<font color='red'>**A: 60 starts to be OK**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **3 - Statistical completion**\n",
    "\n",
    "## <span style=\"color:brown\"> Problem of pseudo-inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le sinograme modifié\n",
    "m_modified = m_perfect.clone().detach()\n",
    "m_modified[6400:6464] = 0 \n",
    "\n",
    "m_modified_array = model_radon.vector2matrix(m_modified, [181,64])\n",
    "\n",
    "#Reconstruire avec A\n",
    "f_reconstruct2 = torch.mv(pinvA,m_modified)\n",
    "f_reconstruct2_array = model_radon.vector2matrix(f_reconstruct2, [64,64])\n",
    "f_reconstruct2_array = np.transpose(f_reconstruct2_array)\n",
    "\n",
    "print('Compute new formula of pseudo-inverse')\n",
    "regu = 1e1\n",
    "if device == \"cuda:0\":\n",
    "    pinvA2 = np.dot(lin.inv(np.dot(np.transpose(A.cpu().numpy()),A.cpu().numpy())+regu*np.eye(64*64)),np.transpose(A.cpu().numpy()))\n",
    "else:\n",
    "    pinvA2 = np.dot(lin.inv(np.dot(np.transpose(A.numpy()),A.numpy())+regu*np.eye(64*64)),np.transpose(A.numpy()))\n",
    "pinvA2 = torch.from_numpy(pinvA2)\n",
    "pinvA2 = pinvA2.type(torch.FloatTensor)\n",
    "\n",
    "#Reconstruire avec A avec la nouvelle pinv\n",
    "f_reconstruct3 = torch.mv(pinvA2,m_modified)\n",
    "f_reconstruct3_array = model_radon.vector2matrix(f_reconstruct3, [64,64])\n",
    "f_reconstruct3_array = np.transpose(f_reconstruct3_array)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 4.5))\n",
    "\n",
    "ax1.set_title(\"Input image\")\n",
    "pcm1 = ax1.matshow(im_array, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.set_title(\"Sinogram\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "pcm2 = ax2.matshow(m_perfect_array, cmap='gray')\n",
    "\n",
    "ax3.set_title(\"Reconstructed image\")\n",
    "pcm3 = ax3.matshow(f_perfect_array, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "fig.colorbar(pcm1,ax=ax1)\n",
    "fig.colorbar(pcm2,ax=ax2)\n",
    "fig.colorbar(pcm3,ax=ax3)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig2, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 4.5))\n",
    "\n",
    "ax1.set_title(\"Input image\")\n",
    "pcm1 = ax1.matshow(im_array, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.set_title(\"Modified Sinogram w one measument forced to zero\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "pcm2 = ax2.matshow(m_modified_array, cmap='gray')\n",
    "\n",
    "ax3.set_title(\"Reconstructed image with a modified sinogram\")\n",
    "pcm3 = ax3.matshow(f_reconstruct2_array, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "fig2.colorbar(pcm1,ax=ax1)\n",
    "fig2.colorbar(pcm2,ax=ax2)\n",
    "fig2.colorbar(pcm3,ax=ax3)\n",
    "fig2.tight_layout()\n",
    "\n",
    "fig3, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 4.5))\n",
    "\n",
    "ax1.set_title(\"Input image\")\n",
    "pcm1 = ax1.matshow(im_array, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.set_title(\"Sinogram w one measument forced to zero\")\n",
    "ax2.set_xlabel(\"Projection angle (deg)\")\n",
    "ax2.set_ylabel(\"Projection position (pixels)\")\n",
    "pcm2 = ax2.matshow(m_modified_array, cmap='gray')\n",
    "\n",
    "ax3.set_title(\"Reconstructed image w new version of pinv\")\n",
    "pcm3 = ax3.matshow(f_reconstruct3_array, cmap='gray')\n",
    "ax3.set_axis_off()\n",
    "\n",
    "fig3.colorbar(pcm1,ax=ax1)\n",
    "fig3.colorbar(pcm2,ax=ax2)\n",
    "fig3.colorbar(pcm3,ax=ax3)\n",
    "fig3.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see on those figures that the backprojection matrix seems to be ill-conditioned for small variations in the sinogram. For example, if we force a column of the sinogram to zero, the reconstructed image ins't good at all. If we see changing pixels values of the sinogram as adding noise to it, an other method of computing the pseudo-inverse matrix could solve this issue introducing a regularisation parameter. \n",
    "\n",
    "The next step consist of filling sinogram's missing values using statistical completion and compare the reconstruction with previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Statistical completion\n",
    "\n",
    "The idea of statistical completion is to give a value for missing data depending on statistics from a dataset. In the example below taken from [1] we can see that the value of a certain pixel in the image is correlated with the values of other pixels (here between coefficient 7 and 2).\n",
    "\n",
    "<img src=\"fig/Hadamard_coeff.PNG\" alt=\"m and A\" style=\"width: 70%;\"/>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:brown\"> Mean and covariance\n",
    "\n",
    "Instead of computing a new pseudo-inverse matrix from the reduced forward radon matrix A, we can se the problem as a full sinogram with missing measurement. Statistical completion of those missing data show promising result in [1]. We can use the STL-10 image library to determine statistical information in order to improve low angle resolution measurements.\n",
    "\n",
    "[1] 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI), Apr 2020, Iowa City, United States. pp.619-623.\n",
    "⟨10.1109/ISBI45749.2020.9098390⟩\n",
    "[hal-02342766v2](https://hal.archives-ouvertes.fr/hal-02342766v2/document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean and covariance matrix\n",
    "Mean_radon = torch.load(saved_data+'Mean_Q64D64.pt', map_location='cpu')\n",
    "Cov_radon = torch.load(saved_data+'Cov_Q64D64.pt', map_location='cpu')\n",
    "#Mean_radon = torch.load('Mean_Q64D64.pt', map_location='cpu')\n",
    "#Cov_radon = torch.load('Cov_Q64D64.pt', map_location='cpu')\n",
    "\n",
    "Mean_radon_array = model_radon.vector2matrix(Mean_radon, [181,64])\n",
    "\n",
    "plt.matshow(Mean_radon_array, cmap='gray')\n",
    "plt.title(\"Average sinogram of every image of STL10\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\">  Statistical completion for consecutive measurement angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbReconstruct = 3\n",
    "listAngles = np.array([20, 60, 100, 150])\n",
    "\n",
    "for i in range(0,nbReconstruct):\n",
    "   \n",
    "    #Tronquer le sinogramme après un certain nombre d'angles d'acquisition\n",
    "    m_reduced = m_perfect[:listAngles[i]*64]\n",
    "\n",
    "    #Séparation des moyennes des pixels. mu1 étant l'acquisition et mu2 les pixel à boucher\n",
    "    mu1 = Mean_radon[:listAngles[i]*64,0]\n",
    "    mu2 = Mean_radon[listAngles[i]*64:,0]\n",
    "\n",
    "    #Séparation des covariances des pixels. Simga1 covariance de l'acquisition, Sigma21 la covariance des pixels acquis et non acquis\n",
    "    Sigma1 = Cov_radon[:64*listAngles[i],:64*listAngles[i]]\n",
    "    Sigma21 = Cov_radon[64*listAngles[i]:,:64*listAngles[i]]\n",
    "\n",
    "    #Complétion statistique\n",
    "    diff = m_reduced-mu1\n",
    "\n",
    "    sigma1_np = Sigma1.numpy()\n",
    "\n",
    "    pinvs = lin.pinv(sigma1_np)\n",
    "\n",
    "    pinvSigma1 = torch.from_numpy(pinvs)\n",
    "\n",
    "    sMix = torch.matmul(Sigma21,pinvSigma1)\n",
    "\n",
    "    y2 = mu2 + torch.mv(torch.matmul(Sigma21,pinvSigma1),diff)\n",
    "\n",
    "    B = torch.mv(sMix,m_reduced)\n",
    "    B_np = B.numpy()\n",
    "    W = mu2 - torch.mv(sMix,mu1)\n",
    "    W_np = W.numpy()\n",
    "    \n",
    "    m_complete = torch.zeros(64*181)\n",
    "    m_complete[:64*listAngles[i]] = m_reduced\n",
    "    m_complete[64*listAngles[i]:] = y2\n",
    "\n",
    "    m_complete_array = model_radon.vector2matrix(m_complete, [181,64])    \n",
    "\n",
    "    f_filled = torch.mv(pinvA2,m_complete)\n",
    "\n",
    "    f_filled_array = model_radon.vector2matrix(f_filled, [64,64])\n",
    "    f_filled_array = np.transpose(f_filled_array)    \n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 4.5))\n",
    "\n",
    "    ax1.set_title(\"Sinogram\")\n",
    "    ax1.set_xlabel(\"Projection angle (deg)\")\n",
    "    ax1.set_ylabel(\"Projection position (pixels)\")\n",
    "    pcm1 = ax1.matshow(m_complete_array, cmap='gray')\n",
    "\n",
    "    ax2.set_title(\"Reconstructed image\")\n",
    "    pcm2 = ax2.matshow(f_filled_array, cmap='gray')\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    fig.colorbar(pcm1,ax=ax1)\n",
    "    fig.colorbar(pcm2,ax=ax2)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest statistical completion algorithm separates the acquired and the not acquired data with a treshold. We can observe that the completed sinogram looks great. Nevertheless the reconstruction is not ideal because most of the measurements are with acquisition angles which are close to each other. A smarter idea would be to complete multiple holes in the sinogram while spacing acquisition angles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\">  Statistical completion for linear spaced measurement angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbReconstruct = 4\n",
    "listAngles = np.array([5, 10, 20, 60])\n",
    "\n",
    "mu = Mean_radon.numpy()\n",
    "sigma = Cov_radon.numpy()\n",
    "\n",
    "for i in range(0,nbReconstruct):\n",
    "    \n",
    "    #Create holes\n",
    "    angles = model_radon.generateActivationAngles(listAngles[i])\n",
    "    m_perfect_holes = torch.zeros(listAngles[i]*64)\n",
    "    m_unperfect = torch.zeros(181*64)\n",
    "    count = 0\n",
    "    for j in range(0,181):\n",
    "        if (angles[j] == 1):\n",
    "            m_perfect_holes[count*64:count*64+64] = m_perfect[j*64:j*64+64]\n",
    "            m_unperfect[j * 64:j * 64 + 64] =m_perfect[j*64:j*64+64]\n",
    "            count = count + 1   \n",
    "            \n",
    "    #Statistical completion\n",
    "    muTuple = model_radon.separateMu(mu,angles,listAngles[i])\n",
    "    sigmaTuple = model_radon.separateSigma(sigma,angles,listAngles[i])\n",
    "    networkTuple = model_radon.computeUnknownData(muTuple[0], muTuple[1], sigmaTuple[0], sigmaTuple[1],angles,listAngles[i])\n",
    "\n",
    "    W = torch.from_numpy(networkTuple[0])\n",
    "    W = W.type(torch.FloatTensor)\n",
    "    B = torch.from_numpy(networkTuple[1])\n",
    "    B = B.type(torch.FloatTensor)\n",
    "\n",
    "    m_filled_bias = torch.mv(W,m_perfect_holes) + B\n",
    "\n",
    "    #afficher le sinogrames bouché avec Biais\n",
    "    m_filled_bias_array = model_radon.vector2matrix(m_filled_bias, [181,64])\n",
    "\n",
    "    #reconstruire l'image\n",
    "    f_reconstructed = torch.mv(pinvA2,m_filled_bias)\n",
    "    f_reconstructed_array = model_radon.vector2matrix(f_reconstructed, [64,64])\n",
    "    f_reconstructed_array = np.transpose(f_reconstructed_array)\n",
    "\n",
    "    Areduced = model_radon.radonSpecifyAngles(A, model_radon.generateAngles(listAngles[i]))\n",
    "    Areduced = Areduced.type(torch.FloatTensor)\n",
    "    if device == \"cuda:0\":\n",
    "        pinvAreduced = lin.pinv(Areduced.cpu().numpy())\n",
    "    else:\n",
    "        pinvAreduced = lin.pinv(Areduced.numpy())\n",
    "    pinvAreduced = torch.from_numpy(pinvAreduced)\n",
    "    pinvAreduced = pinvAreduced.type(torch.FloatTensor)\n",
    "    f_poor = torch.mv(pinvAreduced,torch.mv(Areduced,f[:,0]))\n",
    "    f_poor_array = model_radon.vector2matrix(f_poor, [64,64])\n",
    "    f_poor_array = np.transpose(f_poor_array)    \n",
    "\n",
    "    #Afficher les résultats\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22, 4.5))\n",
    "\n",
    "    ax1.set_title(\"Sinogram\")\n",
    "    ax1.set_xlabel(\"Projection angle (deg)\")\n",
    "    ax1.set_ylabel(\"Projection position (pixels)\")\n",
    "    pcm1 = ax1.matshow(m_filled_bias_array, cmap='gray')\n",
    "\n",
    "    ax2.set_title(\"Reconstructed image w {} angles statistical completion\".format(listAngles[i]))\n",
    "    pcm2 = ax2.matshow(f_reconstructed_array, cmap='gray')\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    ax3.set_title(\"Reconstructed image w {} angles\".format(listAngles[i]))\n",
    "    pcm3 = ax3.matshow(f_poor_array, cmap='gray')\n",
    "    ax3.set_axis_off()    \n",
    "    \n",
    "    fig.colorbar(pcm1,ax=ax1)\n",
    "    fig.colorbar(pcm2,ax=ax2)\n",
    "    fig.colorbar(pcm3,ax=ax3)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we can observe a sort of noise apearing with the increase of measured angles. This might come from the value of the regularisation parameter for the pseudo inverse used for reconstruction with statistical completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **4 - Deep-learning Image reconstruction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image reconstruction via deep neural netoworks aims to find an analytical non-linear mapping $\\mathcal{G}^*$ such that \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{G}^*(\\mathbf{m}) \\approx \\mathbf{f}.\n",
    "\\label{eq:mapping} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "In order to achieve such purpose, we consider a neural network $\\mathcal{G}_\\Omega$ with parameters $\\Omega$.\n",
    "The weights are then chosen to maximise the cost function :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Omega^* = \\underset{\\mathbf{f}}{\\text{argmax}} \\sum_{i=0}^{S-1} \\| \\mathcal{G}_\\Omega(\\mathbf{m}_i) - \\mathbf{f}_i\\|^2_1 + \\mathcal{R}(\\Omega)\n",
    "\\label{eq:fn} \\tag{2}\n",
    "\\end{equation*}\n",
    "Where $(\\mathbf{m}_i , \\mathbf{f}_i)_{i\\in \\{0, \\dots S-1\\}}$ are the samples of a supervised image dataset. $\\mathcal{R}$ is a regularisation function with the purpose of stabilizing the training of the neural network.\n",
    "The choice of $\\mathcal{R}$ may have a big impact on the resulting reconstructor. Amongst the most common choices of $\\mathcal{R}$, we can have $\\mathcal{R}(.) = \\|.\\|^2_2$ or $\\mathcal{R}(.) = \\|.\\|_1$ for instance.\n",
    "\n",
    "For this study we will consider $\\mathcal{R}(.) = \\alpha \\|.\\|^2_2$, where $\\alpha$ is a positive constant that will impact how important $\\mathcal{R}$ is with respect to the rest of the cost function.\n",
    "\n",
    "As convolutional layers have proven to be particularly successful in dealing with images, we like to map the measured sinogram $\\mathbf{m}$ into the image domain to get $\\tilde{\\mathbf{f}}$, a raw linear estimation of $\\mathbf{f}$. \n",
    "\n",
    "<img src=\"fig/network.png\" alt=\"m and A\" style=\"width: 100%;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Explain why we chose to map the sinogram in the image domain via the Moore-Penrose pseudo-inverse rather than learning a mapping from scratch alongside with the rest of the convolutional reconstructor.**</font>\n",
    "\n",
    "<font color='red'>**A: The answer is two-fold. The first answer is that we know that convolutional layers have shown great success in exploiting spacial redundancies of natural images, so we would like to apply the neural network on the image domain. Do note however that several studies have also shown that convolutional layers can be used on sinograms, and to great success. So it's not a compulsorey projection, but a choice. The second part of the answer is that we needed a mapping from the synogram to the image domain. While we could learn everything, we would end up with a lot of parameters to learn : a linear reconstructor would have $D\\times \\theta \\times, Q^2$ parameters.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spyrit.learning.model_Had_DCAN import Weight_Decay_Loss\n",
    "from spyrit.learning.nets import train_model\n",
    "\n",
    "\n",
    "net_types = ['c0mp', 'comp','pinv', 'free']\n",
    "net_arch = 2\n",
    "regularisation = 1e-7\n",
    "\n",
    "num_epochs=3\n",
    "batch_size=256\n",
    "reg=1e-7\n",
    "lr=1e-3\n",
    "step_size=20\n",
    "gamma=0.2\n",
    "checkpoint_model=\"\"\n",
    "checkpoint_interval=0\n",
    "model_root='./models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.functional.to_grayscale,\n",
    "     transforms.Resize((img_size, img_size)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=data_root+\"train\", transform=transform)\n",
    "trainloader = \\\n",
    "    torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=data_root+\"test\", transform=transform)\n",
    "testloader = \\\n",
    "    torch.utils.data.DataLoader(testset, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "dataloaders = {'train': trainloader, 'val': testloader}\n",
    "inputs, labels = next(iter(dataloaders['val']))\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "print(im_array.shape)\n",
    "\n",
    "im_tensor = torch.from_numpy(im_array)\n",
    "m = torch.mv(Areduced,f[:,0])\n",
    "test_batch = 1\n",
    "color = 0\n",
    "# inputs[0, 0, :, :] = im_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: What is the shape of every sample of the dataset? Explain what every dimension corresponds to?**</font>\n",
    "\n",
    "<font color='red'>**A: \\[Batch_size, channels, height, width\\]**</font>\n",
    "\n",
    "<font color='blue'>**Q: Why is it important to normalize all the data from the original dataset?**</font>\n",
    "\n",
    "<font color='red'>**A: Normallized data (in particular 0 mean data) helps stabilizing the training of the Deep neural network. It's also important when the raw data has several orders of magnitude to ensure that your neural networks gets a well defined operating range. As a non-linear reconstructor, it might not work as well if the data has several orders of magnitude.**</font>\n",
    "\n",
    "## <span style=\"color:brown\"> Training a neural network reconstructor from scratch for 3 epochs\n",
    "\n",
    "<font color='blue'>**Q: Complete the code : compute Areduced and pinvAreduced as the forward operator and the pseudo-inverse for 20 projections.**</font>\n",
    "\n",
    "\n",
    "<font color='red'>**A: They've already done it in the previous sections, so they should know how to do it. But I also want them to understand that the Pinv is directly used in the deep-neural reconstructor.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amt = 4\n",
    "nbAngles = 20\n",
    "\n",
    "###################  TO BE COMPLETED\n",
    "Areduced = model_radon.radonSpecifyAngles(A, model_radon.generateAngles(nbAngles))\n",
    "Areduced = Areduced.type(torch.FloatTensor)\n",
    "if device == \"cuda:0\":\n",
    "    pinvAreduced = lin.pinv(Areduced.cpu().numpy())\n",
    "else:\n",
    "    pinvAreduced = lin.pinv(Areduced.numpy())\n",
    "pinvAreduced = torch.from_numpy(pinvAreduced)\n",
    "pinvAreduced = pinvAreduced.type(torch.FloatTensor)\n",
    "####################################\n",
    "\n",
    "model = model_radon.compNet(img_size, pixel_size, nbAngles, A = Areduced, pinvA = pinvAreduced, variant=net_arch)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "loss = nn.MSELoss();\n",
    "criterion = Weight_Decay_Loss(loss);\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr);\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "model, train_info = train_model(model, criterion, \\\n",
    "        optimizer, scheduler, dataloaders, device, model_root, num_epochs=num_epochs,\\\n",
    "        disp=True, do_checkpoint=checkpoint_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Compare the ground truth to the Moore-Penrose pseudo-inverse, and the deep neural reconstuctor.**</font>\n",
    "\n",
    "<font color='red'>**A: Just want them to understand that they just need to add rec[i_test, 0, :, :].cpu(). That way they use their understanding of the dimensions of the samples. I also want them to send their images to the cpu() to understand that for pytorch, it's important to know where the vectors are.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(test_amt):\n",
    "    # Choosing random image in STL10\n",
    "    i_test = np.random.randint(0, inputs.shape[0])\n",
    "    \n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize =(20,10))\n",
    "    fig.suptitle('', fontsize=16)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title(\"Ground-truth\")\n",
    "    aff = ax.imshow(inputs[i_test, 0, :, :].cpu(), cmap='gray') #Complete here\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.set_title(\"Radon pinvNet \")\n",
    "    rec = model.evaluate_fcl(inputs)\n",
    "    aff = ax.imshow(rec[i_test, 0, :, :].cpu(), cmap='gray') #Complete here\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.set_title(\"Corrected image\")\n",
    "    rec = model.evaluate(inputs)\n",
    "    aff = ax.imshow(rec[i_test, 0, :, :].cpu(), cmap='gray') #Complete here\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: What seems to be the effect of training the neural network for few epochs?**</font>\n",
    "\n",
    "<font color='red'>**A: We can see that our reconstructor after a few epochs seems to smooth the image a lot. While this helps remove some artifacts, some still remains. Also we lost most of the details in the reconstructed images since the reconstruction is too smooth.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Testing a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_types = ['c0mp', 'comp','pinv', 'free']\n",
    "net_arch = 2\n",
    "num_epoch = 100\n",
    "list_angles = np.array([20, 40, 60])\n",
    "learning_rate = 1e-3\n",
    "step_size = 10\n",
    "gamma = 0.5\n",
    "batch_size = 1000\n",
    "regularisation = 1e-7\n",
    "\n",
    "\n",
    "\n",
    "test_amt = 4\n",
    "nbAngles = 20\n",
    "inputs, labels = next(iter(dataloaders['val']))\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Deducing model file name\n",
    "suffix = '_Q_{}_D_{}_T_{}_epo_{}_lr_{}_sss_{}_sdr_{}_bs_{}_reg_{}'.format(\\\n",
    "               img_size, pixel_size, nbAngles, num_epoch, learning_rate, step_size,\\\n",
    "               gamma, batch_size, regularisation)\n",
    "# title = 'nets/NET_'+ net_types[net_arch] + suffix\n",
    "title = data_root + 'nets/NET_'+ net_types[net_arch] + suffix\n",
    "\n",
    "# Loading model\n",
    "model = model_radon.compNet(img_size, pixel_size, nbAngles, variant=net_arch)\n",
    "model = model.to(device)\n",
    "model_out_path = \"{}.pth\".format(title)\n",
    "model.load_state_dict(torch.load(model_out_path, map_location=torch.device('cpu')))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(test_amt):\n",
    "    # Choosing random image in STL10\n",
    "    i_test = np.random.randint(0, inputs.shape[0])\n",
    "    \n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize =(20,10))\n",
    "    fig.suptitle('', fontsize=16)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title(\"Ground-truth\")\n",
    "    aff = ax.imshow(inputs[i_test, 0, :, :].cpu(), cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.set_title(\"Radon pinvNet \")\n",
    "    rec = model.evaluate_fcl(inputs)\n",
    "    aff = ax.imshow(rec[i_test, 0, :, :].cpu(), cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.set_title(\"Corrected image\")\n",
    "    rec = model.evaluate(inputs)\n",
    "    aff = ax.imshow(rec[i_test, 0, :, :].cpu(), cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: What is the impact of training a deep neural network until it converges?**</font>\n",
    "\n",
    "<font color='red'>**A: We can observe that the background seems to possess many fewer artifacts than before, the images while fairly smooth manage to retain many more details than it previously did.**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:brown\"> Comparing neural Netoworks for several numbers of projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(list_angles.size):\n",
    "    print(\"Acquisition of \" + list_angles[index].astype(str) + \" angles\")\n",
    "    # Deducing model file name\n",
    "    suffix = '_Q_{}_D_{}_T_{}_epo_{}_lr_{}_sss_{}_sdr_{}_bs_{}_reg_{}'.format(\\\n",
    "                   img_size, pixel_size, list_angles[index], num_epoch, learning_rate, step_size,\\\n",
    "                   gamma, batch_size, regularisation)\n",
    "    # title = 'nets/NET_'+ net_types[net_arch] + suffix\n",
    "    title = data_root + 'nets/NET_'+ net_types[net_arch] + suffix\n",
    "    \n",
    "    # loading model\n",
    "    model = model_radon.compNet(img_size, pixel_size, list_angles[index], variant=net_arch)\n",
    "    model = model.to(device)\n",
    "    model_out_path = \"{}.pth\".format(title)\n",
    "    model.load_state_dict(torch.load(model_out_path, map_location=torch.device('cpu'))) \n",
    "    model_bis = model;\n",
    "    \n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize =(20,10))\n",
    "    fig.suptitle('', fontsize=16)\n",
    "    \n",
    "    ax = axs[0]\n",
    "    ax.set_title(\"Sinograme\")\n",
    "    rec = model.forward_acquire(inputs, test_batch, color, img_size, img_size)\n",
    "    rec_array = model_radon.vector2matrix(rec[0, :, 0, 0].cpu(), [list_angles[index], 64])\n",
    "    aff = ax.imshow(rec_array, cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax)\n",
    "\n",
    "    ax = axs[1]\n",
    "    ax.set_title(\"Radon pinvNet \")\n",
    "    rec = model.evaluate_fcl(inputs)\n",
    "    aff = ax.imshow(rec[0, 0, :, :].cpu(), cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "\n",
    "    ax = axs[2]\n",
    "    ax.set_title(\"Corrected image\")\n",
    "    rec = model.evaluate(inputs)\n",
    "    aff = ax.imshow(rec[0, 0, :, :].cpu(), cmap='gray')\n",
    "    fig.colorbar(aff, ax=ax,fraction=0.046,pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Q: Conclude on the limits of Deep-neural reconstructors.**</font>\n",
    "\n",
    "\n",
    "<font color='red'>**A: When the data is heavily down-sampled, it then even deep-neural reconstructors cannot overcome the resulting artefacts. The students may understand that even imperfect reconstructions are the best one can obtain sometimes.**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:brown\"> **Conclusion**\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this hands on session, you should be able to :\n",
    "- Understand the importance of modeling the forward operator of an inverse problem.\n",
    "- Reconstruct an image from measurement data thanks to linear reconstructors such as the Moore-Penrose pseudo-inverse.\n",
    "- Reconstruct an image from measurement data thanks to non-linear reconstructors such as convolutional neural networks : the impact of training for a small number of epochs, and how to integrate linear reconstructors to deep-learning methods.\n",
    "- Understand the limits of reconstruction methods when the data is undersampled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
